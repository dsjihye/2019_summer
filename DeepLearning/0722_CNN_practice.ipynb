{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For wide monitor\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hello = tf.constant('Hello, TensorFlow!') # 노드 생성, 이름은 hello\n",
    "sess = tf.Session() # 메모리에 올리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello, TensorFlow!'\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(hello))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_csv = pd.read_csv('mnist_train.csv', header=None, skiprows=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59999, 785)\n"
     ]
    }
   ],
   "source": [
    "print(mnist_csv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0  51 159 253 159  50   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0  48 238 252 252 252 237   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0  54 227 253 252 239 233 252  57   6   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0  10  60 224 252 253 252 202  84\n",
      " 252 253 122   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0 163 252 252 252 253 252 252  96 189 253 167   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0  51 238 253 253 190 114 253\n",
      " 228  47  79 255 168   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0  48 238 252 252 179  12  75 121  21   0   0 253 243  50   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0  38 165 253 233 208  84   0\n",
      "   0   0   0   0   0 253 252 165   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   7 178 252 240  71  19  28   0   0   0   0   0   0 253 252 195\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0  57 252 252  63   0   0\n",
      "   0   0   0   0   0   0   0 253 252 195   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0 198 253 190   0   0   0   0   0   0   0   0   0   0 255\n",
      " 253 196   0   0   0   0   0   0   0   0   0   0   0  76 246 252 112   0\n",
      "   0   0   0   0   0   0   0   0   0 253 252 148   0   0   0   0   0   0\n",
      "   0   0   0   0   0  85 252 230  25   0   0   0   0   0   0   0   0   7\n",
      " 135 253 186  12   0   0   0   0   0   0   0   0   0   0   0  85 252 223\n",
      "   0   0   0   0   0   0   0   0   7 131 252 225  71   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0  85 252 145   0   0   0   0   0   0   0  48\n",
      " 165 252 173   0   0   0   0   0   0   0   0   0   0   0   0   0   0  86\n",
      " 253 225   0   0   0   0   0   0 114 238 253 162   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0  85 252 249 146  48  29  85 178 225\n",
      " 253 223 167  56   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0  85 252 252 252 229 215 252 252 252 196 130   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0  28 199 252 252 253 252 252\n",
      " 233 145   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0  25 128 252 253 252 141  37   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "print(mnist_csv[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(mnist_csv, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41999, 785)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18000, 785)\n"
     ]
    }
   ],
   "source": [
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_csv[1][0] # label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41999, 10) (41999, 784)\n",
      "(18000, 10) (18000, 784)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "y_train, X_train = np_utils.to_categorical(train[:, 0]), train[:, 1:]\n",
    "y_test, X_test = np_utils.to_categorical(test[:,0]), test[:, 1:]\n",
    "print(y_train.shape, X_train.shape)\n",
    "print(y_test.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.53333333\n",
      " 0.99607843 0.99607843 1.         0.99607843 0.99607843 0.99607843\n",
      " 0.69803922 0.61960784 0.61960784 0.4745098  0.09019608 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.91764706 0.99607843 0.99607843\n",
      " 0.99607843 0.99607843 0.99607843 0.99607843 0.99607843 0.99607843\n",
      " 0.99607843 0.99607843 0.90980392 0.47058824 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.58431373 0.99607843 0.74117647 0.63529412 0.63529412\n",
      " 0.63529412 0.29019608 0.55686275 0.63529412 0.69019608 0.99607843\n",
      " 0.99607843 0.90980392 0.09019608 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.01176471\n",
      " 0.01568627 0.00784314 0.         0.         0.         0.\n",
      " 0.         0.         0.00392157 0.49411765 0.99607843 0.99607843\n",
      " 0.24313725 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.07843137 0.20392157\n",
      " 0.67058824 0.96078431 0.99607843 0.93333333 0.12941176 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.12941176\n",
      " 0.         0.6627451  0.9372549  0.99607843 0.99607843 0.99607843\n",
      " 0.99607843 0.60392157 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.04705882\n",
      " 0.20784314 0.4745098  0.58431373 0.76078431 0.96078431 0.99215686\n",
      " 0.98823529 0.70196078 0.88235294 0.63137255 0.03529412 0.00392157\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.54901961 0.99607843 0.99607843\n",
      " 0.99607843 0.99607843 0.99607843 0.99607843 0.81568627 0.0745098\n",
      " 0.07843137 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.69411765 0.99607843 0.99607843 0.99607843 0.99607843\n",
      " 0.99607843 0.99607843 0.99607843 0.45882353 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.33333333\n",
      " 0.80392157 0.68235294 0.43137255 0.43137255 0.43137255 0.81176471\n",
      " 0.99607843 0.87058824 0.05490196 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.03529412 0.80784314 0.99607843\n",
      " 0.4        0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.30196078 0.99607843 0.47058824 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.03921569 0.99607843 0.47058824 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.21176471 0.99607843\n",
      " 0.47058824 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.24705882 0.0745098  0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.05098039 0.84705882 0.99607843 0.47058824 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.22352941\n",
      " 0.98431373 0.79215686 0.1254902  0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.56862745\n",
      " 0.99607843 0.95294118 0.11372549 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.24313725 0.99215686 0.99607843\n",
      " 0.94509804 0.41960784 0.01960784 0.01568627 0.         0.00784314\n",
      " 0.01960784 0.20784314 0.77254902 0.97647059 0.99215686 0.41568627\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.52156863 0.99607843 0.99607843 0.99607843\n",
      " 0.99607843 0.92156863 0.63921569 0.75294118 0.99607843 0.99607843\n",
      " 0.99607843 0.99607843 0.4745098  0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.01568627 0.24705882 0.71372549 0.97647059 0.99607843 0.99607843\n",
      " 0.99607843 0.99607843 0.99607843 0.96470588 0.49019608 0.28235294\n",
      " 0.02352941 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.20784314 0.78431373 0.99607843 0.99607843 0.99607843\n",
      " 0.78039216 0.29803922 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.53333333\n",
      " 0.99607843 0.99607843 1.         0.99607843 0.99607843 0.99607843\n",
      " 0.69803922 0.61960784 0.61960784 0.4745098  0.09019608 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.91764706 0.99607843 0.99607843\n",
      " 0.99607843 0.99607843 0.99607843 0.99607843 0.99607843 0.99607843\n",
      " 0.99607843 0.99607843 0.90980392 0.47058824 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.58431373 0.99607843 0.74117647 0.63529412 0.63529412\n",
      " 0.63529412 0.29019608 0.55686275 0.63529412 0.69019608 0.99607843\n",
      " 0.99607843 0.90980392 0.09019608 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.01176471\n",
      " 0.01568627 0.00784314 0.         0.         0.         0.\n",
      " 0.         0.         0.00392157 0.49411765 0.99607843 0.99607843\n",
      " 0.24313725 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.07843137 0.20392157\n",
      " 0.67058824 0.96078431 0.99607843 0.93333333 0.12941176 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.12941176\n",
      " 0.         0.6627451  0.9372549  0.99607843 0.99607843 0.99607843\n",
      " 0.99607843 0.60392157 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.04705882\n",
      " 0.20784314 0.4745098  0.58431373 0.76078431 0.96078431 0.99215686\n",
      " 0.98823529 0.70196078 0.88235294 0.63137255 0.03529412 0.00392157\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.54901961 0.99607843 0.99607843\n",
      " 0.99607843 0.99607843 0.99607843 0.99607843 0.81568627 0.0745098\n",
      " 0.07843137 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.69411765 0.99607843 0.99607843 0.99607843 0.99607843\n",
      " 0.99607843 0.99607843 0.99607843 0.45882353 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.33333333\n",
      " 0.80392157 0.68235294 0.43137255 0.43137255 0.43137255 0.81176471\n",
      " 0.99607843 0.87058824 0.05490196 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.03529412 0.80784314 0.99607843\n",
      " 0.4        0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.30196078 0.99607843 0.47058824 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.03921569 0.99607843 0.47058824 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.21176471 0.99607843\n",
      " 0.47058824 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.24705882 0.0745098  0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.05098039 0.84705882 0.99607843 0.47058824 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.22352941\n",
      " 0.98431373 0.79215686 0.1254902  0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.56862745\n",
      " 0.99607843 0.95294118 0.11372549 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.24313725 0.99215686 0.99607843\n",
      " 0.94509804 0.41960784 0.01960784 0.01568627 0.         0.00784314\n",
      " 0.01960784 0.20784314 0.77254902 0.97647059 0.99215686 0.41568627\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.52156863 0.99607843 0.99607843 0.99607843\n",
      " 0.99607843 0.92156863 0.63921569 0.75294118 0.99607843 0.99607843\n",
      " 0.99607843 0.99607843 0.4745098  0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.01568627 0.24705882 0.71372549 0.97647059 0.99607843 0.99607843\n",
      " 0.99607843 0.99607843 0.99607843 0.96470588 0.49019608 0.28235294\n",
      " 0.02352941 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.20784314 0.78431373 0.99607843 0.99607843 0.99607843\n",
      " 0.78039216 0.29803922 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "#a<=X<=b\n",
    "#0<=X-a<=b-a\n",
    "#0<=(X-a)/(b-a)<=1\n",
    "#scaling해야함. 딥러닝에서는 이거 안해도 잘 나오긴 함..\n",
    "X_train = (X_train-0)/255 # normalize\n",
    "X_test = (X_test-0)/255 # normalize\n",
    "print(X_train[0])\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1cc2fff4e48>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.imshow(np.reshape(X_train[0], (28,28)), cmap=plt.cm.Blues) # 컬러 이미지면 (28,28,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1cc2f8c3f60>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.reshape(X_train[0], (28,28)), cmap=plt.cm.gray_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신경망 입출력 디자인\n",
    "import tensorflow as tf\n",
    "X = tf.placeholder(tf.float32, [None, 784]) # constanct는 변하지않는 상수 # placeholder는 임시적으로 저장해놓을 수 있는 통 (데이터가 들락날락할 수 있는)\n",
    "X_img = tf.reshape(X, [-1, 28, 28, 1])\n",
    "y = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# (28, 28, 1)\n",
    "W1 = tf.Variable(tf.random_normal([3,3,1,16], stddev=0.01)) # (3,3)채널 16 필터개수\n",
    "L1 = tf.nn.conv2d(X_img, W1, strides=[1,1,1,1], padding='SAME') \n",
    "# (28, 28, 16)\n",
    "L1 = tf.nn.relu(L1)\n",
    "L1 = tf.nn.max_pool(L1, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME') # ksize 이미지 크기 stride \n",
    "# (14, 14, 16)\n",
    "W2 = tf.Variable(tf.random_normal([3,3,16,32], stddev=0.01))\n",
    "L2 = tf.nn.conv2d(L1, W2, strides=[1,1,1,1], padding='SAME')\n",
    "L2 = tf.nn.relu(L2)\n",
    "L2 = tf.nn.max_pool(L2, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "# (7, 7, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "L2_flat=tf.reshape(L2, [-1, 7 * 7 * 32]) #Flatten\n",
    "W3 =tf.Variable(tf.random_normal([7 * 7 * 32, 10], stddev =0.01))\n",
    "b =tf.Variable(tf.random_normal([10]))\n",
    "logits =tf.matmul (L2_flat, W3) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-37-89f52302af20>:5: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 아키텍처를 설계해보세요 - con pool 의 디자인을 바꾸는것. 호출 개수를 바꾸는 것\n",
    "# 하이퍼파타미터를 설계해보세요 - 필터 개수, 사이즈 이런걸 바꾸는 것.\n",
    "#구분할 것\n",
    "#서로다른 cnn 5개 만들어보세요\n",
    "\n",
    "learning_rate = 0.001\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_epochs=10\n",
    "batch_size=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 loss= 0.722796172\n",
      "Epoch: 0002 loss= 0.267389250\n",
      "Epoch: 0003 loss= 0.162899581\n",
      "Epoch: 0004 loss= 0.115962917\n",
      "Epoch: 0005 loss= 0.092872243\n",
      "Epoch: 0006 loss= 0.078940497\n",
      "Epoch: 0007 loss= 0.068956407\n",
      "Epoch: 0008 loss= 0.061201615\n",
      "Epoch: 0009 loss= 0.054840349\n",
      "Epoch: 0010 loss= 0.049408719\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(training_epochs): # 눈높이를 몇번 되감느냐\n",
    "    avg_loss = 0\n",
    "    total_batch = int(X_train.shape[0]/batch_size)\n",
    "    for idx in range(total_batch):\n",
    "        num = (idx*batch_size)%(X_train.shape[0])\n",
    "        batch_xs = X_train[num:(num+batch_size)]\n",
    "        batch_ys = y_train[num:(num+batch_size)]\n",
    "        feed_dict = {X:batch_xs, y:batch_ys}\n",
    "        c, _ = sess.run([loss, optimizer], feed_dict=feed_dict)\n",
    "        avg_loss+=c/total_batch\n",
    "    print(\"Epoch:\", \"%04d\"%(epoch+1), \"loss=\", \"{:.9f}\".format(avg_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9773333\n"
     ]
    }
   ],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(y_test, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(\"Accuracy:\", sess.run(accuracy, feed_dict={X:X_test, y:y_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예쁜 confusion_matrix\n",
    "def plot_confusion_matrix(pred, label, class_info):\n",
    "    cnf_matrix = confusion_matrix(label, pred)\n",
    "    plt.figure()\n",
    "    plt.imshow(chf_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    tick_marks = np.arange(len(class_info))\n",
    "    plt.xticks(tick_marks, class_info, rotation=45)\n",
    "    plt.yticks(tick_marks, class_info)\n",
    "    thresh = cnf_matrix.max()/2.\n",
    "    for i, j in itertools.product(range(cnf_matrix.shape[0]),\n",
    "                                 range(cnf_matrix.shape[1])):\n",
    "        plt.text(j, i, cnf_matrix[i,j], horizontalalignment=\"center\",\n",
    "                )\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "> def\n",
    "plot_confusion_matrix pred , label, class_info\n",
    ">\n",
    "cnf_matrix = confusion_matrix (label, pred\n",
    ">\n",
    "plt.figure\n",
    ">\n",
    "plt.imshow cnf_matrix , interpolation='nearest', cmap plt.cm.Blues\n",
    ">\n",
    "tick_marks = np.arange len class_info\n",
    ">\n",
    "plt.xticks tick_marks , class_info , rotation=\n",
    ">\n",
    "plt.yticks tick_marks , class_info\n",
    "> thresh =\n",
    "cnf_matrix.max () /\n",
    "> for\n",
    "i , j in itertools.product ( cnf_matrix.shape [0]),\n",
    "range( cnf_matrix.shape [\n",
    ">\n",
    "plt.text (j, i , cnf_matrix i , j], horizontalalignment =\"center\",\n",
    "> color=\"white\" if\n",
    "cnf_matrix i , j] > thresh else \"\n",
    ">\n",
    "plt.tight_layout\n",
    ">\n",
    "plt.ylabel ('True\n",
    ">\n",
    "plt.xlabel ('Predicted\n",
    ">\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "prediction = tf.argmax(logits, 1) #argument중에서 max인 값을 받아준다\n",
    "pred = sess.run(prediction, feed_dict={X:X_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 3 4 ... 2 0 8]\n"
     ]
    }
   ],
   "source": [
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1722    0    6    0    0    0    6    0    4    1]\n",
      " [   0 1959    9    6    2    0    6    4   14    0]\n",
      " [   2    4 1792   16    0    0    0    4    8    3]\n",
      " [   1    0    5 1832    0    5    0    1    5    1]\n",
      " [   0    3    6    4 1693    0    6    2    5   22]\n",
      " [   3    0    0   27    0 1581    6    1   15    9]\n",
      " [   4    2    2    1    1    2 1708    0    4    0]\n",
      " [   2    6   15   42    3    1    0 1808    4   28]\n",
      " [   6    2    2    8    2    4    3    1 1765   11]\n",
      " [   1    2    0    8    5    1    1    3    9 1732]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(label, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
